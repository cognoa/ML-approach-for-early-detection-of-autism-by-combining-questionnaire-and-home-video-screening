{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=====[ Setup - don't modify ]=====\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "import autism_evaluator_structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Combine Training Dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFilePath = #Point this to your own training sets\n",
    "f = open(dataFilePath, 'rU')\n",
    "dictReader = csv.DictReader(f, delimiter='\\t')\n",
    "data = []\n",
    "for row in dictReader:\n",
    "    data.append(row)\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFilePath = #Point this to your own training sets\n",
    "f = open(dataFilePath, 'rU')\n",
    "dictReader = csv.DictReader(f, delimiter='\\t')\n",
    "data = []\n",
    "for row in dictReader:\n",
    "    data.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFilePath = #Point this to your own training sets\n",
    "f = open(dataFilePath, 'rU')\n",
    "dictReader = csv.DictReader(f, delimiter='\\t')\n",
    "data = []\n",
    "for row in dictReader:\n",
    "    data.append(row)\n",
    "\n",
    "df3 = pd.DataFrame(data)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df1.append(df2).append(df3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert some columns to int type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in ['age_years', 'age_months', 'insturment_module']:\n",
    "    df[column] = pd.to_numeric(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter by age and group into two age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[(df['age_years']>1) &(df['age_years']<7)]\n",
    "df['age_group'] = demographic_df['age_years'].apply(lambda x: '<=3' if x<4 else '>=4')\n",
    "\n",
    "df[['age_group', 'outcome', 'age_years']].groupby(['age_group', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some sanity checks on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['sample_source','outcome']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df[df.instrument_module==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.groupby(['sample_source']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.sort_values(by=['age_years']).groupby(['age_years']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[df.insturment_module==2]\n",
    "df2.groupby(['sample_source']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.sort_values(by=['age_years']).groupby(['age_years', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit age depending on instrument module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_training = [{},{},{}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod1_min_years = 1 if age_as_feature==True else 2\n",
    "mod2_min_years = 1 if age_as_feature==True else 3\n",
    "\n",
    "video_training[1]['data'] = df[ (df.instrument_module==1) &  (df.age_years>=mod1_min_years) & (df.age_years<=max_years)].reset_index(drop=True)\n",
    "video_training[1]['q_columns'] = columns_about(video_training[1]['data'], 'instument_')\n",
    "video_training[1]['age_columns'] = ['age_years', 'age_months']\n",
    "video_training[1]['gender_columns'] = ['gender']\n",
    "\n",
    "\n",
    "video_training[2]['data'] = df[ (df.instrument_module==2) &  (df.age_years>=mod2_min_years) & (df.age_years<=max_years)].reset_index(drop=True)\n",
    "video_training[2]['q_columns'] = columns_about(video_training[2]['data'], 'instrument_')\n",
    "video_training[2]['age_columns'] = ['age_years', 'age_months']\n",
    "video_training[2]['gender_columns'] = ['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_training[1]['data'].groupby(['age_years', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_training[2]['data'].groupby(['age_years', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'q cols: ', video_training[module]['q_columns']\n",
    "print 'age cols: ', video_training[module]['columns']\n",
    "print 'gender cols: ', video_training[module]['gender_columns']\n",
    "feature_columns = video_training[module]['q_columns'] + video_training[module]['columns'] + video_training[module]['gender_columns']\n",
    "print 'feature cols: ', feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map any value outside {0,1,2,3,4} to 'missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if map_features==True:\n",
    "    for feature in video_training[module]['q_columns']:\n",
    "        video_training[module]['data'][feature] = video_training[module]['data'][feature].apply(lambda x: x if x in ['0', '1', '2', '3', '4'] else 'missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in feature_columns:\n",
    "    print feature\n",
    "    print video_training[module]['data'][feature].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we encode different features differently - this is the list features for each encoding type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrete_encoding_features = []\n",
    "one_hot_encoding_features = []\n",
    "if run_encoding == 'default':\n",
    "    scalar_encoding_features = video_training[module]['age_columns']\n",
    "    one_hot_encoding_features = video_training[module]['gender_columns']+video_training[module]['q_columns']\n",
    "    presence_of_behavior_features = []\n",
    "elif run_encoding == 'production':\n",
    "    scalar_encoding_features = video_training[module]['age_columns']\n",
    "    presence_of_behavior_features = video_training[module]['gender_columns']+video_training[module]['q_columns']\n",
    "elif run_encoding == 'scalar':\n",
    "    scalar_encoding_features = video_training[module]['age_columns']+video_training[module]['gender_columns']+video_training[module]['q_columns']\n",
    "    presence_of_behavior_features = []\n",
    "else:\n",
    "    raise ValueError('Error, run_encoding: '+run_encoding+' not understood')\n",
    "\n",
    "\n",
    "feature_encoding_map = {}\n",
    "for feature in scalar_encoding_features:\n",
    "    feature_encoding_map[feature] = 'scalar'\n",
    "for feature in one_hot_encoding_features:\n",
    "    feature_encoding_map[feature] = 'one_hot'\n",
    "for feature in discrete_encoding_features:\n",
    "    feature_encoding_map[feature] = 'discrete'\n",
    "for feature in presence_of_behavior_features:\n",
    "    feature_encoding_map[feature] = 'presence_of_behavior'\n",
    "\n",
    "print 'for run_desc: ', run_desc, ', feature_encoding_map: ', feature_encoding_map\n",
    "print 'feature_columns now: ', feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create missing data and inject loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Define loss/missing data instructions\n",
    "lossColumnsToDo = [[], video_training[1]['q_columns'], video_training[2]['q_columns']]\n",
    "lossInstructions = MissingDataInstructions.get_missing_instructions_from_SQL(lossColumnsToDo, minProb=0.01, \n",
    "                                                                             desc='clinical')\n",
    "\n",
    "print 'For run_desc: ', run_desc, ', inject_loss: ', inject_loss\n",
    "if inject_loss is not None and inject_loss=='proportional':\n",
    "    video_training[module]['data'] = inject_proportional_loss_when_presence_encoding(video_training[module]['data'], outcome_key='outcome',\n",
    "                    instructions=None, missing_value='missing', prior_autism_frac=0.5, module=module, validation=True)\n",
    "\n",
    "for feature in feature_columns:\n",
    "    print feature\n",
    "    print video_training[module]['data'][feature].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "date_string = time.strftime(\"%-m.%-d.%y\")\n",
    "\n",
    "output_directory = 'output/'\n",
    "filename_prefix = \"Instrument\"+str(module)+\".\"+run_desc+'_'+date_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are ML training constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "outcome_class_priors =  [(1.0/2.0), (1.0/2.0)]       # IN CLINICAL CENTRES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with all data as a warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 200\n",
    "criterion = \"gini\"\n",
    "max_features = 'log2'\n",
    "max_depth=5\n",
    "class_weight = None\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "number_of_features_to_keep = 15\n",
    "\n",
    "#sprinkle some random features\n",
    "video_training[module]['data']['random1'] = np.random.choice(3, len(video_training[module]['data']), p=[0.1, 0.6, 0.3])\n",
    "video_training[module]['data']['random2'] = np.random.choice(4, len(video_training[module]['data']), p=[0.25, 0.25, 0.25, 0.25])\n",
    "video_training[module]['data']['random3'] = np.random.choice(2, len(video_training[module]['data']), p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "sample_weights = balance_dataset_on_dimensions(video_training[module]['data'], balance_dimensions, verbose=False)\n",
    "\n",
    "model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "                    all_data_model(video_training[module]['data'], feature_columns,\n",
    "                    feature_encoding_map, outcome_column, sample_weights, dunno_range,\n",
    "                    RandomForestClassifier,  n_estimators = n_estimators, criterion = criterion,\n",
    "                    max_features = max_features, class_weight = class_weight, max_depth=max_depth)\n",
    "  \n",
    "important_features = get_important_features(model, features, 0.001)\n",
    "    \n",
    "metrics = get_classifier_performance_metrics(outcome_classes, outcome_class_priors,\n",
    "            video_training[module]['data'][outcome_column], y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs)\n",
    "print 'metrics: ', metrics\n",
    "for feature in important_features:\n",
    "    print(feature)\n",
    "    print(\"\\n\") \n",
    "print_classifier_performance_metrics(outcome_classes, metrics)\n",
    "\n",
    "top_feature_columns =  get_best_features(important_features, number_of_features_to_keep, ['=', '_behavior_present'], [])\n",
    "n_features = 10 if module==1 else 9\n",
    "default_top_N_features = cp.deepcopy(top_feature_columns[:n_features])\n",
    "\n",
    "print 'for run_desc: ', run_desc, ', top features: ', default_top_N_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model repeatedly and keep tabs on which features get used most often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 200\n",
    "criterion = \"gini\"\n",
    "max_features = 'log2'\n",
    "class_weight = None\n",
    "max_depth=5\n",
    "\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "\n",
    "feature_tally = {}\n",
    "number_of_features_to_keep = 15\n",
    "\n",
    "#do the following many times\n",
    "number_of_tries = 10\n",
    "\n",
    "\n",
    "for i in range(0,number_of_tries):\n",
    "    print 'Starting try ', i, ' out of ', number_of_tries\n",
    "    \n",
    "    #grab a random subsample\n",
    "    dataset_for_this_try = subsample_per_class(video_training[module]['data'], outcome_column, {'autism':0.9, 'not':0.9} )\n",
    "    \n",
    "    #sprinkle some random features\n",
    "    dataset_for_this_try['random1'] = np.random.choice(3, len(dataset_for_this_try), p=[0.1, 0.6, 0.3])\n",
    "    dataset_for_this_try['random2'] = np.random.choice(4, len(dataset_for_this_try), p=[0.25, 0.25, 0.25, 0.25])\n",
    "    dataset_for_this_try['random3'] = np.random.choice(2, len(dataset_for_this_try), p=[0.6, 0.4])\n",
    "    \n",
    "    sample_weights_for_this_try = balance_dataset_on_dimensions(dataset_for_this_try,\n",
    "                                                balance_dimensions, verbose=False)\n",
    "\n",
    "    model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "        all_data_model(dataset_for_this_try, feature_columns+['random1','random2','random3'], \n",
    "        feature_encoding_map, outcome_column, sample_weights_for_this_try, dunno_range, RandomForestClassifier,  \n",
    "        n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "        class_weight = class_weight, max_depth=max_depth)\n",
    "    \n",
    "    important_features = get_important_features(model, features, 0.01)\n",
    "    \n",
    "    top_feature_columns = get_best_features(important_features, number_of_features_to_keep,\n",
    "                                            ['=', '_behavior_present'], ['gender','age_months','age_years'])\n",
    "    for feature in top_feature_columns:\n",
    "        if feature in feature_tally:\n",
    "            feature_tally[feature]+=1\n",
    "        else:\n",
    "            feature_tally[feature]=1\n",
    "\n",
    "tally = sorted(feature_tally.items(), key=lambda pair: pair[1], reverse=True)\n",
    "print tally\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How statistically limited are we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fracs_to_check = np.array(list(np.arange(0.01, 0.1, 0.01)) +\\\n",
    "                list(np.arange(0.1, 0.5, 0.05)) +\\\n",
    "                list(np.arange(0.5, 1., 0.1)) + [1.])\n",
    "n_duplicate_runs=20\n",
    "n_folds=5\n",
    "\n",
    "plot_title=''\n",
    "\n",
    "training_data_statistical_stability_tests(video_training[module]['data'], sample_frac_sizes=fracs_to_check, feature_columns=feature_columns,\n",
    "                  feature_encoding_map=feature_encoding_map, target_column=outcome_column,\n",
    "                  sample_weights=sample_weights, dunno_range=dunno_range, model_function=RandomForestClassifier,\n",
    "                  outcome_classes=outcome_classes, outcome_class_priors=outcome_class_priors,\n",
    "                  cross_validate_group_id='unique_patient_id', n_folds=n_folds, n_duplicate_runs=n_duplicate_runs,\n",
    "                  do_plotting=True, plot_title=plot_title, n_estimators = n_estimators, criterion = criterion,\n",
    "                  max_features = max_features, class_weight = class_weight, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we cross validate to gauge model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 200\n",
    "criterion = \"gini\"\n",
    "max_features = 'log2'\n",
    "class_weight = None\n",
    "max_depth=5\n",
    "#cross_validate_with_groupid=None\n",
    "cross_validate_with_groupid='unique_patient_id'\n",
    "\n",
    "class_weight = None\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "n_folds = 20\n",
    "\n",
    "print 'For module: ', module\n",
    "print 'Using following parameters:'\n",
    "print 'criterion: ', criterion\n",
    "print 'max_features: ', max_features\n",
    "print 'max_depth: ', max_depth\n",
    "print 'n_estimators: ', n_estimators\n",
    "print 'features: ', feature_columns\n",
    "\n",
    "output = cross_validate_model(video_training[module]['data'], sample_weights, feature_columns,\n",
    "                feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, \n",
    "                outcome_class_priors, RandomForestClassifier,  groupid=cross_validate_with_groupid, \n",
    "                n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "                class_weight = class_weight, max_depth=max_depth)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for best decision forest model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'About to run grid search for ', run_desc, ', module: ', module\n",
    "print 'ages in dataset: ', video_training[module]['data']['age_years'].value_counts()\n",
    "print 'balance on: ', balance_dimensions\n",
    "print 'Features to use in grid search:'\n",
    "for feature in feature_columns:\n",
    "    print feature, ', encoding: ', feature_encoding_map[feature], ', values: ', video_training[module]['data'][feature].value_counts()\n",
    "\n",
    "n_autism = len(video_training[module]['data'][video_training[module]['data']['outcome']=='autism'].index)\n",
    "n_not = len(video_training[module]['data'][video_training[module]['data']['outcome']=='not'].index)\n",
    "print 'n_autism: ', n_autism\n",
    "print 'n_not: ', n_not\n",
    "print 'n_total: ', len(video_training[module]['data'].index)\n",
    "assert n_autism + n_not == len(video_training[module]['data'].index)\n",
    "\n",
    "#this is where we output to\n",
    "output_filename = output_directory+filename_prefix+\".gridSearch.modelParams.csv\"\n",
    "\n",
    "criterion = [\"entropy\"]\n",
    "max_features = ['log2']\n",
    "max_depth = [4,5,6,7]\n",
    "n_estimators = [200]\n",
    "\n",
    "#cross_validate_with_groupid=None\n",
    "cross_validate_with_groupid='unique_patient_id'\n",
    "\n",
    "param_combinations = get_combinations([criterion, max_features, max_depth, n_estimators])\n",
    "\n",
    "#these are bootstrapping parameters\n",
    "bootstrapping_number_of_tries = 10     #run every node in the grid search this many times and average out the resulting metrics\n",
    "bootstrapping_sample_percent = 0.9    #for every run, random-sample this percentage of the dataset (stratified by target class) \n",
    "\n",
    "\n",
    "#these static params are problem specific\n",
    "n_folds = 20\n",
    "\n",
    "#this dunno range param is outside of the ML model so let's fix it to some convenient values for now\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "print 'For module: ', module\n",
    "print 'Do grid search for best model parameters using:'\n",
    "print 'features: ', feature_columns\n",
    "sys.stdout.flush()\n",
    "\n",
    "def modeling_function(param_combination):\n",
    "    def sampling_function_per_try(dataset):\n",
    "        sample = subsample_per_class(dataset, outcome_column, {'autism':bootstrapping_sample_percent, 'not':bootstrapping_sample_percent})\n",
    "        return sample\n",
    "    def ml_function_per_try(dataset_per_try):\n",
    "        sample_weights_per_try = balance_dataset_on_dimensions(dataset_per_try, balance_dimensions)\n",
    "\n",
    "        metrics = cross_validate_model(dataset_per_try, sample_weights_per_try,\n",
    "                feature_columns, feature_encoding_map, outcome_column, dunno_range,\n",
    "                n_folds, outcome_classes, outcome_class_priors, RandomForestClassifier, groupid=cross_validate_with_groupid,\n",
    "                criterion = param_combination[0], max_features = param_combination[1],\n",
    "                max_depth=param_combination[2], n_estimators = param_combination[3])\n",
    "        return metrics['overall_metrics']\n",
    "    averaged_metrics, averaged_metrics_err =  bootstrap(video_training[module]['data'], bootstrapping_number_of_tries, sampling_function_per_try,\n",
    "                                  ml_function_per_try, return_errs=True, verbose=False)\n",
    "    print 'For param_combination: ', param_combination, ', AUC: ', averaged_metrics['without_dunno']['auc']\n",
    "    sys.stdout.flush()\n",
    "    return averaged_metrics, averaged_metrics_err\n",
    "\n",
    "\n",
    "\n",
    "reporting_function = lambda param_combination, (averaged_metrics, averaged_metrics_err): [ averaged_metrics['without_dunno']['auc'],\n",
    "                                                                  averaged_metrics_err['without_dunno']['auc'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_precision_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['reallife_precision_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                                  averaged_metrics_err['without_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_precision_per_class']['not'],\n",
    "                                                                  averaged_metrics['without_dunno']['reallife_precision_per_class']['not'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_recall_per_class']['not'], \n",
    "                                                                  averaged_metrics_err['without_dunno']['dataset_recall_per_class']['not'],\n",
    "                                                                  n_autism,\n",
    "                                                                  n_not,\n",
    "                                                                 ]\n",
    "\n",
    "\n",
    "#run grid search\n",
    "report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "    \n",
    "#write outputs to file\n",
    "output_file = open(output_filename,'w')\n",
    "header = ','.join(['criterion','max_features', 'max_depth', 'n_trees','AUC','AUC err', 'autism precision [Dataset]', \n",
    "                   'autism precision [Reallife]', 'autism recall', 'autism recall err', 'not precision [Dataset]',\n",
    "                   'not precision [Reallife]', 'not recall', 'not recall err', 'n_autism', 'n_not'])\n",
    "output_file.write(header+\"\\n\")\n",
    "for line in report:\n",
    "    output_file.write(','.join([str(x) for x in line]))\n",
    "    output_file.write(\"\\n\")\n",
    "output_file.close()\n",
    "\n",
    "print 'Grid search done for run_desc: ', run_desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best dunno range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balance_dimensions#this is where we output to\n",
    "output_filename = output_directory+filename_prefix+\".gridSearch.dunnoRange.csv\"\n",
    "\n",
    "\n",
    "#these are bootstrapping parameters\n",
    "bootstrapping_number_of_tries = 10     #run every node in the grid search this many times and average out the resulting metrics\n",
    "bootstrapping_sample_percent = 0.9    #for every run, random-sample this percentage of the dataset (stratified by target class) \n",
    "\n",
    "#cross_validate_with_groupid=None\n",
    "cross_validate_with_groupid='unique_patient_id'\n",
    "\n",
    "\n",
    "#these static params are problem specific\n",
    "n_folds = 20\n",
    "\n",
    "#these params are outside of the ML model so let's fix them to some convenient values for now\n",
    "dunno_range_min = [0.01, 0.1, 0.2, 0.3, 0.4, 0.45, 0.49]\n",
    "dunno_range_max = [0.51, 0.55, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "param_combinations = get_combinations([dunno_range_min, dunno_range_max])\n",
    "\n",
    "\n",
    "\n",
    "def modeling_function(param_combination):\n",
    "    def sampling_function_per_try(dataset):\n",
    "        sample = subsample_per_class(dataset, outcome_column, {'autism':bootstrapping_sample_percent,\n",
    "                                                'not':bootstrapping_sample_percent})\n",
    "        return sample\n",
    "    def ml_function_per_try(dataset_per_try):\n",
    "        print 'Running param_combination: ', param_combination\n",
    "        sys.stdout.flush()\n",
    "        sample_weights_per_try = balance_dataset_on_dimensions(dataset_per_try, balance_dimensions)\n",
    "\n",
    "        metrics = cross_validate_model(dataset_per_try, sample_weights_per_try,\n",
    "                    feature_columns, feature_encoding_map, outcome_column,\n",
    "                    (param_combination[0], param_combination[1]), n_folds, outcome_classes,\n",
    "                    outcome_class_priors, RandomForestClassifier, groupid=cross_validate_with_groupid, criterion = criterion,\n",
    "                    max_features = max_features,  max_depth = max_depth, n_estimators = n_estimators)\n",
    "        return metrics['overall_metrics']\n",
    "    \n",
    "    averaged_metrics =  bootstrap(video_training[module]['data'], bootstrapping_number_of_tries, sampling_function_per_try, ml_function_per_try)\n",
    "    print 'For param_combination: ', param_combination, ', AUC: ', averaged_metrics['without_dunno']['auc'], ' +/- ',\\\n",
    "                 averaged_metrics_err['without_dunno']['auc']\n",
    "    sys.stdout.flush()\n",
    "    return averaged_metrics\n",
    "\n",
    "\n",
    "\n",
    "reporting_function = lambda param_combination, averaged_metrics: [ averaged_metrics['with_dunno']['dataset_classification_rate'],\n",
    "                                                          averaged_metrics['with_dunno']['reallife_classification_rate'],\n",
    "                                                          averaged_metrics['with_dunno']['dataset_precision_per_class']['autism'],\n",
    "                                                          averaged_metrics['with_dunno']['reallife_precision_per_class']['autism'],\n",
    "                                                          averaged_metrics['with_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                          averaged_metrics['with_dunno']['dataset_precision_per_class']['not'],\n",
    "                                                          averaged_metrics['with_dunno']['reallife_precision_per_class']['not'],\n",
    "                                                          averaged_metrics['with_dunno']['dataset_recall_per_class']['not']\n",
    "                                                        ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#run grid search\n",
    "report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "\n",
    "#write outputs to file\n",
    "output_file = open(output_filename,'w')\n",
    "header = ','.join(['dunno_range_min','dunno_range_max', \n",
    "                'classification rate [Dataset]',\n",
    "                'classification rate [Reallife]',\n",
    "                'autism precision [Dataset]', \n",
    "                'autism precision [Reallife]', \n",
    "                'autism recall', \n",
    "                'not precision [Dataset]', \n",
    "                'not precision [Reallife]', \n",
    "                'not recall'])\n",
    "output_file.write(header+\"\\n\")\n",
    "report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "for line in report:\n",
    "    output_file.write(','.join([str(x) for x in line]))\n",
    "    output_file.write(\"\\n\")\n",
    "output_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimal model parameters and optimal dunno range to cross validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'For module: ', module\n",
    "print 'Using following parameters:'\n",
    "print 'criterion: ', criterion\n",
    "print 'max_features: ', max_features\n",
    "print 'max_depth: ', max_depth\n",
    "print 'n_estimators: ', n_estimators\n",
    "print 'features: ', feature_columns\n",
    "\n",
    "output = cross_validate_model(video_training[module]['data'], sample_weights, feature_columns, feature_encoding_map,\n",
    "                                       outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "                                       RandomForestClassifier,  groupid=cross_validate_with_groupid, n_estimators = n_estimators, \n",
    "                                       criterion = criterion, max_features = max_features, class_weight = class_weight,\n",
    "                                      max_depth=max_depth)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now build the final model using all corresponding samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is where we output to\n",
    "output_filename = output_directory+run_choices+\"_\"+filename_prefix+\".model\"\n",
    "print 'For module: ', module\n",
    "print 'Using following parameters:'\n",
    "print 'criterion: ', criterion\n",
    "print 'max_features: ', max_features\n",
    "print 'max_depth: ', max_depth\n",
    "print 'n_estimators: ', n_estimators\n",
    "print 'feature_columns: ', feature_columns\n",
    "\n",
    "\n",
    "#build model\n",
    "model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "           all_data_model(video_training[module]['data'], feature_columns, feature_encoding_map, outcome_column, \n",
    "           sample_weights, dunno_range, RandomForestClassifier,  n_estimators = n_estimators, criterion = criterion,\n",
    "           max_features = max_features, max_depth=max_depth, class_weight = class_weight)\n",
    "\n",
    "\n",
    "#save features into a separate file\n",
    "output_filename = output_directory+filename_prefix+\".features.txt\"\n",
    "output_file = open(output_filename,'w')\n",
    "ordered_features = sorted(zip(features, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "output_file.write(\"QUESTIONS BY IMPORTANCE:\\n\\n\")\n",
    "written_already = []\n",
    "for feature in [x[0].split('=')[0] for x in ordered_features]:\n",
    "    if feature not in written_already:\n",
    "        written_already += [feature]\n",
    "        output_file.write(feature)\n",
    "        output_file.write(\"\\n\")\n",
    "output_file.write(\"\\n\\nFEATURES BY IMPORTANCE:\\n\\n\")\n",
    "for pair in ordered_features:\n",
    "    output_file.write(str(pair[0])+\"\\t\"+str(pair[1]))\n",
    "    output_file.write(\"\\n\")\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

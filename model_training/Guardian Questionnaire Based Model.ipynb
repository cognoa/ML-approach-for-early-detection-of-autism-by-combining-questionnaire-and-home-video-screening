{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====[ Setup - don't modify ]=====\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFilePath = #Point this to your own training sets\n",
    "f = open(dataFilePath, 'rU')\n",
    "dictReader = csv.DictReader(f)\n",
    "data = []\n",
    "for row in dictReader:\n",
    "    data.append(row)\n",
    "\n",
    "dataset = pd.DataFrame(data)\n",
    "\n",
    "dataset.age_years = dataset.age_years.apply(float)\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "print 'sample source: '\n",
    "print dataset['sample_source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.groupby(['age_years', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby(['sample_source', 'outcome']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we encode different features differently - this is the list features for each encoding type\n",
    "\n",
    "scalar_encoding_features = [ #INSERT LIST OF FEATURES THAT YOU WANT SCALAR-ENCODED\n",
    "]\n",
    "\n",
    "\n",
    "production_one_hot_encoding_features = [ #INSERT LIST OF FEATURES THAT YOU WANT ONE-HOT-ENCODED\n",
    "                            ]\n",
    "\n",
    "\n",
    "production_discrete_encoding_features = [ # INSERT LIST OF FEATURES THAT YOU WANT DISCRETE-ENCODED\n",
    "]\n",
    "\n",
    "\n",
    "if run_encoding == 'default':\n",
    "    one_hot_encoding_features = production_one_hot_encoding_features + production_discrete_encoding_features\n",
    "    discrete_encoding_features = []\n",
    "elif run_encoding == 'production':\n",
    "    one_hot_encoding_features = production_one_hot_encoding_features\n",
    "    discrete_encoding_features = production_discrete_encoding_features\n",
    "elif run_encoding == 'scalar':\n",
    "    one_hot_encoding_features = []\n",
    "    discrete_encoding_features = []\n",
    "    scalar_encoding_features += production_one_hot_encoding_features\n",
    "    scalar_encoding_features += production_discrete_encoding_features\n",
    "else:\n",
    "    raise ValueError('Error, run_encoding: '+run_encoding+' not understood')\n",
    "\n",
    "feature_encoding_map = {}\n",
    "for feature in scalar_encoding_features:\n",
    "    print 'add feature ', feature, ' to feature encoding map'\n",
    "    feature_encoding_map[feature] = 'scalar'\n",
    "for feature in one_hot_encoding_features:\n",
    "    feature_encoding_map[feature] = 'one_hot'\n",
    "for feature in discrete_encoding_features:\n",
    "    feature_encoding_map[feature] = 'discrete'\n",
    "print 'feature_encoding_map: ', feature_encoding_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Guardian Questionnaire Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the dataset on age. The 2-3 range is too sparse, so we include 4 year olds also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_years = 4 if only_young_children else 100\n",
    "min_years = 4 if only_old_children else 0\n",
    "dataset = dataset[(dataset.age_years>=min_years) & (dataset.age_years<=max_years)].reset_index(drop=True)\n",
    "\n",
    "import time\n",
    "date_string = time.strftime(\"%-m.%-d.%y\")\n",
    "\n",
    "output_directory = 'output/'\n",
    "filename_prefix = run_desc+'_'+date_string\n",
    "\n",
    "print 'max_years: ', max_years\n",
    "print 'run_desc: ', run_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding FUSION features (young kids version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (do_feature_engineering and only_young_children) or restricted_features=='young_official':\n",
    "\n",
    "    #HALIM: EXPERIMENTING WITH FUSION FEATURES HERE\n",
    "\n",
    "    #fusion creation function\n",
    "    def max_severity(data_row):\n",
    "        return_value = 'missing'\n",
    "        for data_element in data_row:\n",
    "            try:\n",
    "                value = int(data_element)\n",
    "                if value > 4:\n",
    "                    continue\n",
    "                if return_value == 'missing':\n",
    "                    return_value = value\n",
    "                elif value>return_value:\n",
    "                    return_value = value\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return str(return_value)\n",
    "\n",
    "    #list of fusion features\n",
    "    fusion_features = [ #INSERT YOUR OWN LIST OF FUSION FEATURES HERE \n",
    "    ]\n",
    "        \n",
    "    #fusion feature defintion\n",
    "    for feature in fusion_features:\n",
    "        dataset[feature] = dataset[[feature+'_current', feature+'_ever']].apply(max_severity, axis=1)\n",
    "\n",
    "    #define their feature encoding as 'discrete'\n",
    "    for feature in fusion_features:\n",
    "        if run_encoding == 'default':\n",
    "            feature_encoding_map[feature] = 'one_hot'\n",
    "        elif run_encoding == 'production':\n",
    "            feature_encoding_map[feature] = 'discrete'\n",
    "        elif run_encoding == 'scalar':\n",
    "            feature_encoding_map[feature] = 'scalar'\n",
    "        else:\n",
    "            raise ValueError('Error, run_encoding: '+run_encoding+' not understood')\n",
    "\n",
    "    #include them in our features\n",
    "    print 'adding in fusion_features: ', fusion_features\n",
    "    feature_columns += fusion_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with all data as a warm-up, and do default feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "outcome_class_priors =  [(1.0/2.0), (1.0/2.0)]       # IN CLINICAL CENTRES\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "number_of_features_to_keep = 25\n",
    "\n",
    "print 'balance with balance_dimensions: ', balance_dimensions\n",
    "sample_weights = balance_dataset_on_dimensions(dataset, balance_dimensions, verbose=False)\n",
    "print 'age_as_feature: ', age_as_feature\n",
    "if only_young_children==True:\n",
    "    for index in range(len(dataset)):\n",
    "        if dataset['age_years'][index]==3:\n",
    "            sample_weights[index] *= 3\n",
    "        if dataset['age_years'][index]==2:\n",
    "            sample_weights[index] *= 2\n",
    "            \n",
    "all_results_list = []\n",
    "feature_selection_iterations = 50 if run_choices=='default' else 1\n",
    "cross_validation_age_weights = balance_dataset_on_dimensions(dataset, ['age_years'], verbose=False)\n",
    "\n",
    "for pei in range(feature_selection_iterations):\n",
    "    print 'On pseudo experiment ', pei, ' of ', feature_selection_iterations \n",
    "\n",
    "    model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "        all_data_model(dataset, feature_columns, feature_encoding_map,\n",
    "        outcome_column, sample_weights, dunno_range, RandomForestClassifier,  n_estimators = n_estimators,\n",
    "        criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "  \n",
    "    important_features = get_important_features(model, features, 0.001)\n",
    "    \n",
    "    metrics = get_classifier_performance_metrics(outcome_classes, outcome_class_priors, dataset[outcome_column], y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs)\n",
    "    for feature in important_features:\n",
    "        print(feature)\n",
    "        print(\"\\n\") \n",
    "    print_classifier_performance_metrics(outcome_classes, metrics)\n",
    "\n",
    "    top_feature_columns =  get_best_features(important_features, number_of_features_to_keep, ['='], [])\n",
    "    default_top_N_features = cp.deepcopy(top_feature_columns[:N_for_top_N])\n",
    "    print 'default_top_N_features: ', default_top_N_features, ', len: ', len(default_top_N_features)\n",
    "    \n",
    "    iteration_results_dict = {}\n",
    "    for feature in features:\n",
    "        if feature in default_top_N_features:\n",
    "            iteration_results_dict[feature+'_present'] = 1\n",
    "        else:\n",
    "            iteration_results_dict[feature+'_present'] = 0\n",
    "\n",
    "    ### Now compare each iteration of performance metrics \n",
    "    n_folds = 20\n",
    "    if only_young_children==False:\n",
    "        output = cross_validate_model(dataset, sample_weights, default_top_N_features,\n",
    "            feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "            RandomForestClassifier,  validation_weights=cross_validation_age_weights, n_estimators = n_estimators,\n",
    "            criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "    else:\n",
    "        output = cross_validate_model_with_addon(dataset, sample_weights, default_top_N_features,\n",
    "           feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "           RandomForestClassifier,  validation_weights=cross_validation_age_weights, n_estimators = n_estimators,\n",
    "           criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "    iteration_results_dict['AUC'] = output['overall_metrics']['without_dunno']['auc']\n",
    "    iteration_results_dict['autism recall'] = output['overall_metrics']['without_dunno']['dataset_recall_per_class']['autism']\n",
    "    iteration_results_dict['not recall'] = output['overall_metrics']['without_dunno']['dataset_recall_per_class']['not']\n",
    "    iteration_results_dict['autism precision [Dataset]'] = output['overall_metrics']['without_dunno']['dataset_precision_per_class']['autism']\n",
    "    iteration_results_dict['not precision [Dataset]'] = output['overall_metrics']['without_dunno']['dataset_precision_per_class']['not']\n",
    "    iteration_results_dict['autism precision [Reallife]'] = output['overall_metrics']['without_dunno']['reallife_precision_per_class']['autism']\n",
    "    iteration_results_dict['not precision [Reallife]'] = output['overall_metrics']['without_dunno']['reallife_precision_per_class']['not']\n",
    "    all_results_list.append(iteration_results_dict)\n",
    "    print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n",
    "\n",
    "if run_choices=='default':\n",
    "    all_results_df = pd.DataFrame(all_results_list)\n",
    "    print 'all_results_df'\n",
    "    all_results_df.to_csv(output_directory+\"/\"+filename_prefix+'_selection_variations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in sorted(zip(features, model.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with [2-3yolds only] repeatedly and keep tabs on which features get used most often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "\n",
    "feature_tally = {}\n",
    "number_of_features_to_keep = 15\n",
    "\n",
    "print 'allowed features: '\n",
    "for feature in feature_columns:\n",
    "    print 'feature: ', feature, ', encoding: ', feature_encoding_map[feature]\n",
    "    #if 'q46' in feature or 'q60' in feature:\n",
    "    if True:\n",
    "        print 'deatils: ', dataset[feature].value_counts()\n",
    "\n",
    "#do the following many times\n",
    "number_of_tries = 50 if restricted_features == 'tally_top_N' else 1\n",
    "for i in range(0,number_of_tries):\n",
    "    print 'On try number ', i, ' of ', number_of_tries\n",
    "    \n",
    "    if only_young_children:\n",
    "        #grab a random subsample of 2-3 year olds only\n",
    "        tally_dataset = dataset[dataset.age_years<4].reset_index(drop=True)\n",
    "    else:\n",
    "        tally_dataset = cp.deepcopy(dataset)\n",
    "\n",
    "    dataset_for_this_try = subsample_per_class(tally_dataset, outcome_column, {'autism':0.9, 'not':0.9} )\n",
    "    \n",
    "     #sprinkle some random features\n",
    "     dataset_for_this_try['random1'] = np.random.choice(3, len(dataset_for_this_try), p=[0.1, 0.6, 0.3])\n",
    "     dataset_for_this_try['random2'] = np.random.choice(4, len(dataset_for_this_try), p=[0.25, 0.25, 0.25, 0.25])\n",
    "     dataset_for_this_try['random3'] = np.random.choice(2, len(dataset_for_this_try), p=[0.6, 0.4])\n",
    "\n",
    "    if i==0:\n",
    "        print 'balancing dimensions: ', balance_dimensions\n",
    "        print 'features and encodings: '\n",
    "        for feature in feature_columns:\n",
    "            print 'feature: ', feature, ', encoding: ', feature_encoding_map[feature]\n",
    "        print 'dataset_for_this_try has len: ', len(dataset_for_this_try.index), ', ages: ', dataset_for_this_try['age_years'].value_counts() \n",
    "        \n",
    "    sample_weights_for_this_try = balance_dataset_on_dimensions(dataset_for_this_try, balance_dimensions,\n",
    "                                                verbose=False)\n",
    "\n",
    "    #here we bump 3 years olds sample weights by a factor of 2 relative to the 2 year olds\n",
    "    if only_young_children==True:\n",
    "        for index in range(len(dataset_for_this_try)):\n",
    "            if dataset_for_this_try['age_years'][index]==3:\n",
    "                sample_weights_for_this_try[index] *= 2\n",
    "\n",
    "       \n",
    "    model, features, y_predicted_without_dunno, y_predicted_with_dunno,\\\n",
    "        y_predicted_probs = all_data_model(dataset_for_this_try,\n",
    "        feature_columns, feature_encoding_map, outcome_column,\n",
    "        sample_weights_for_this_try, dunno_range, RandomForestClassifier,  n_estimators = n_estimators,\n",
    "        criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "    \n",
    "    important_features = get_important_features(model, features, 0.01)\n",
    "    \n",
    "    top_feature_columns = get_best_features(important_features, number_of_features_to_keep, ['='], [])\n",
    "    for feature in top_feature_columns:\n",
    "        if feature in feature_tally:\n",
    "            feature_tally[feature]+=1\n",
    "        else:\n",
    "            feature_tally[feature]=1\n",
    "\n",
    "tally = sorted(feature_tally.items(), key=lambda pair: pair[1], reverse=True)\n",
    "tally\n",
    "\n",
    "print 'tally: ', tally\n",
    "top_N_tally_features_superset = [ele[0] for ele in tally][:N_for_top_N+10]\n",
    "print 'top_N_tallly_features_superset: ', top_N_tally_features_superset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if restricted_features == 'tally_top_N':\n",
    "     base_feature_sel_tuple = [(ele, default_top_N_features.index(ele), None if ele not in top_N_tally_features else top_N_tally_features.index(ele)) for ele in default_top_N_features]\n",
    "     tally_feature_sel_tuple = [(ele, top_N_tally_features.index(ele), None if ele not in default_top_N_features else default_top_N_features.index(ele)) for ele in top_N_tally_features]\n",
    "     print 'base_feature_sel_tuple: ', base_feature_sel_tuple\n",
    "     print '\\n\\n'\n",
    "     print 'tally_feature_sel_tuple: ', tally_feature_sel_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we restrict the feature set to the ones chosen often in the experiment above, and we build an all-data model to find the feature importance order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [x[0] for x in tally if (x[1]>=25 and 'random' not in x[0]) ]\n",
    "\n",
    "for feature in feature_columns:\n",
    "    print 'feature: ', feature\n",
    "    print 'in df? ', (feature in dataset.columns)\n",
    "    \n",
    "print 'After possible restrictions,  features: ', feature_columns\n",
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "\n",
    "number_of_features_to_keep = N_for_top_N\n",
    "\n",
    "sample_weights = balance_dataset_on_dimensions(dataset, balance_dimensions, verbose=False)\n",
    "\n",
    "if only_young_children==True:\n",
    "    for index in range(len(dataset)):\n",
    "        if dataset['age_years'][index]==3:\n",
    "            sample_weights[index] *= 3\n",
    "        if dataset['age_years'][index]==2:\n",
    "            sample_weights[index] *= 2\n",
    "\n",
    "\n",
    "print 'feature_encoding_map[age_years]: ', feature_encoding_map['age_years']\n",
    "print 'age years value counts: ', dataset['age_years'].value_counts()\n",
    "model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "    all_data_model(dataset, feature_columns, feature_encoding_map, outcome_column, sample_weights,\n",
    "    dunno_range, RandomForestClassifier,  n_estimators = n_estimators, criterion = criterion,\n",
    "    max_features = max_features, max_depth=max_depth)\n",
    "\n",
    "important_features = get_important_features(model, features, 0.001)\n",
    "top_feature_columns = get_best_features(important_features, number_of_features_to_keep, ['='], [])\n",
    "print 'top_feature_columns end up being: ', top_feature_columns\n",
    "\n",
    "\n",
    "metrics = get_classifier_performance_metrics(outcome_classes, outcome_class_priors, dataset[outcome_column], y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, metrics)\n",
    "\n",
    "ordered_features = sorted(zip(features, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "print \"\\nEncoded features by importance:\"\n",
    "for feature in ordered_features:\n",
    "    print feature\n",
    "\n",
    "    \n",
    "print 'feature_encoding_map: ', feature_encoding_map\n",
    "\n",
    "print 'Further refine this superset of features: ', sorted(feature_columns)\n",
    "print 'To this set: ', sorted(top_feature_columns)\n",
    "if restricted_features == 'tally_top_N':\n",
    "    feature_columns = top_feature_columns\n",
    "    base_feature_sel_tuple = [(ele, default_top_N_features.index(ele), None if ele not in feature_columns else feature_columns.index(ele)) for ele in default_top_N_features]\n",
    "    tally_feature_sel_tuple = [(ele, feature_columns.index(ele), None if ele not in default_top_N_features else default_top_N_features.index(ele)) for ele in feature_columns]\n",
    "    print 'base_feature_sel_tuple: ', base_feature_sel_tuple\n",
    "    print '\\n\\n'\n",
    "    print 'tally_feature_sel_tuple: ', tally_feature_sel_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we cross validate to gauge model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "class_weight = None#\"balanced\" #balanced_subsample\"\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "n_folds = 20\n",
    "\n",
    "print 'Validate autism vs non-autism weights'\n",
    "dataset['weights'] = sample_weights\n",
    "autism_df = dataset[dataset['outcome']=='autism']\n",
    "not_df = dataset[dataset['outcome']=='not']\n",
    "assert len(autism_df.index) + len(not_df.index) == len(dataset.index)\n",
    "print 'young_dataset autism sum weights: ', np.sum(autism_df['weights'].values)\n",
    "print 'young_dataset not sum weights: ', np.sum(not_df['weights'].values)\n",
    "\n",
    "\n",
    "\n",
    "cross_validation_age_weights = balance_dataset_on_dimensions(dataset, ['age_years'], verbose=False)\n",
    "\n",
    "#cross validate\n",
    "print 'Cross validate with dataset of length: ', len(dataset.index)\n",
    "print 'len young_sample_weights: ', len(sample_weights)\n",
    "if only_young_children==False:\n",
    "    output = cross_validate_model(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier,  validation_weights=cross_validation_age_weights, n_estimators = n_estimators,\n",
    "        criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "else:\n",
    "    output = cross_validate_model_with_addon(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier,  validation_weights=cross_validation_age_weights, n_estimators = n_estimators,\n",
    "        criterion = criterion, max_features = max_features, max_depth=max_depth)\n",
    "#print 'output has len: ', len(young_output), ', vals: ', young_output\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding aggregate severity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_feature_engineering:\n",
    "\n",
    "\n",
    "    #aggregate severity creation functions\n",
    "    def max_severity(data_row):\n",
    "        return_value = 'missing'\n",
    "        for data_element in data_row:\n",
    "            try:\n",
    "                value = int(data_element)\n",
    "                if value<0 or value>4:\n",
    "                    continue\n",
    "                if return_value == 'missing':\n",
    "                    return_value = value\n",
    "                elif value>return_value:\n",
    "                    return_value = value\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return str(return_value)\n",
    "    def min_severity(data_row):\n",
    "        return_value = 'missing'\n",
    "        for data_element in data_row:\n",
    "            try:\n",
    "                value = int(data_element)\n",
    "                if value<0 or value>4:\n",
    "                    continue\n",
    "                if return_value == 'missing':\n",
    "                    return_value = value\n",
    "                elif value<return_value:\n",
    "                    return_value = value\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return str(return_value)\n",
    "\n",
    "    def count_severity_level(data_row, severity_level):\n",
    "        return_value = 0\n",
    "        for data_element in data_row:\n",
    "            if data_element==severity_level:\n",
    "                return_value += 1\n",
    "        return return_value\n",
    "\n",
    "\n",
    "    #list of aggregate severity features\n",
    "    aggregate_severity_features = ['max_severity',\n",
    "                                   'min_severity', \n",
    "                                   'severity_0_count',\n",
    "                                   'severity_1_count',\n",
    "                                   'severity_2_count',\n",
    "                                   'severity_3_count',\n",
    "                                   'severity_4_count',\n",
    "                                  ]\n",
    "\n",
    "\n",
    "    #list of features to aggregate over\n",
    "    features_to_aggregate_over = feature_columns\n",
    "\n",
    "\n",
    "    #aggregate severity feature defintion\n",
    "    dataset['max_severity'] = dataset[features_to_aggregate_over].apply(max_severity, axis=1)\n",
    "    dataset['min_severity'] = dataset[features_to_aggregate_over].apply(min_severity, axis=1)\n",
    "    dataset['severity_0_count'] = dataset[features_to_aggregate_over].apply(lambda row: count_severity_level(row, \"0\"), axis=1)\n",
    "    dataset['severity_1_count'] = dataset[features_to_aggregate_over].apply(lambda row: count_severity_level(row, \"1\"), axis=1)\n",
    "    dataset['severity_2_count'] = dataset[features_to_aggregate_over].apply(lambda row: count_severity_level(row, \"2\"), axis=1)\n",
    "    dataset['severity_3_count'] = dataset[features_to_aggregate_over].apply(lambda row: count_severity_level(row, \"3\"), axis=1)\n",
    "    dataset['severity_4_count'] = dataset[features_to_aggregate_over].apply(lambda row: count_severity_level(row, \"4\"), axis=1)\n",
    "\n",
    "\n",
    "    #define their feature encoding as 'discrete'\n",
    "    for feature in aggregate_severity_features:\n",
    "        if run_encoding == 'default':\n",
    "            feature_encoding_map[feature] = 'one_hot'\n",
    "        elif run_encoding == 'production':\n",
    "            if 'count' in feature:\n",
    "                feature_encoding_map[feature] = 'scalar'\n",
    "            else:\n",
    "                feature_encoding_map[feature] = 'discrete'\n",
    "        elif run_encoding == 'scalar':\n",
    "            feature_encoding_map[feature] = 'scalar'      \n",
    "        else:\n",
    "            raise ValueError('Error, run_encoding: '+run_encoding+' not understood')\n",
    "\n",
    "    #include them in our features\n",
    "    print 'add aggregate_severity_features: ', aggregate_severity_features\n",
    "    feature_columns += aggregate_severity_features\n",
    "\n",
    "    dataset[aggregate_severity_features].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the model with all data to see if aggregate features were useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "\n",
    "\n",
    "number_of_features_to_keep = 20\n",
    "\n",
    "sample_weights = balance_dataset_on_dimensions(dataset, balance_dimensions, verbose=False)\n",
    "\n",
    "if only_young_children==True:\n",
    "    for index in range(len(dataset)):\n",
    "        if dataset['age_years'][index]==3:\n",
    "            sample_weights[index] *= 3\n",
    "        if dataset['age_years'][index]==2:\n",
    "            sample_weights[index] *= 2\n",
    "\n",
    "\n",
    "model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "    all_data_model(dataset, feature_columns, feature_encoding_map, outcome_column, sample_weights,\n",
    "    dunno_range, RandomForestClassifier,  n_estimators = n_estimators, criterion = criterion,\n",
    "    max_features = max_features, max_depth=max_depth, class_weight = class_weight)\n",
    "\n",
    "important_features = get_important_features(model, features, 0.001)\n",
    "    \n",
    "metrics = get_classifier_performance_metrics(outcome_classes, outcome_class_priors, dataset[outcome_column], y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, metrics)\n",
    "\n",
    "ordered_features = sorted(zip(features, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "print \"\\nFeatures by importance:\"\n",
    "for feature in ordered_features:\n",
    "    print feature\n",
    "\n",
    "print 'feature_encoding_map: ', feature_encoding_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we cross validate again to gauge model performance with aggregate features added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 200\n",
    "criterion = \"entropy\"\n",
    "max_features = \"log2\"\n",
    "max_depth = 5\n",
    "\n",
    "class_weight = None#\"balanced\" #balanced_subsample\"\n",
    "outcome_column = 'outcome'\n",
    "outcome_classes = ['autism','not']\n",
    "\n",
    "dunno_range = (0.2,0.9)\n",
    "n_folds = 20\n",
    "\n",
    "#cross_validation_age_weights = None\n",
    "cross_validation_age_weights = balance_dataset_on_dimensions(dataset, ['age_years'], verbose=False)\n",
    "print 'feature columns to do and encoding: '\n",
    "for column in feature_columns:\n",
    "    print column, ', ', feature_encoding_map[column]\n",
    "if only_young_children==False:\n",
    "    print 'Do cross validation with age as a feature.'\n",
    "    output = cross_validate_model(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier,  validation_weights=cross_validation_age_weights,  n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "        max_depth=max_depth)\n",
    "else:\n",
    "    print 'Do cross validation without age as a feature.'\n",
    "    output = cross_validate_model_with_addon(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier,  validation_weights=cross_validation_age_weights, n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "        max_depth=max_depth)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n",
    "\n",
    "print 'feature_encoding_map: ', feature_encoding_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best decision forest model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Grid search modeling function\n",
    "print 'balance dimensions: ', balance_dimensions\n",
    "\n",
    "def modeling_function(param_combination):\n",
    "    def sampling_function_per_try(dataset):\n",
    "        sample = subsample_per_class(dataset, outcome_column, {'autism':bootstrapping_sample_percent, 'not':bootstrapping_sample_percent})\n",
    "        return sample\n",
    "    def ml_function_per_try(dataset_per_try):\n",
    "        sample_weights_per_try = balance_dataset_on_dimensions(dataset_per_try, balance_dimensions)\n",
    "        sample_cross_validation_age_weights = balance_dataset_on_dimensions(dataset_per_try, ['age_years'], verbose=False)\n",
    "\n",
    "        dataset_per_try['weights'] = sample_weights_per_try\n",
    "        autism_df = dataset_per_try[dataset_per_try['outcome']=='autism']\n",
    "        not_df = dataset_per_try[dataset_per_try['outcome']=='not']\n",
    "        assert len(autism_df.index) + len(not_df.index) == len(dataset_per_try.index)\n",
    "        if only_young_children==True:\n",
    "            for index in range(len(dataset_per_try)):\n",
    "                if dataset_per_try['age_years'][index]==3:\n",
    "                    sample_weights_per_try[index] *= 3\n",
    "                if dataset_per_try['age_years'][index]==2:\n",
    "                    sample_weights_per_try[index] *= 2\n",
    "\n",
    "        if only_young_children==False:\n",
    "            metrics = cross_validate_model(dataset_per_try, sample_weights_per_try, feature_columns,\n",
    "                        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, \n",
    "                        outcome_class_priors, RandomForestClassifier, validation_weights=sample_cross_validation_age_weights,                         criterion = param_combination[0], \n",
    "                        max_features = param_combination[1], max_depth=param_combination[2], \n",
    "                        n_estimators = param_combination[3])\n",
    "        else:\n",
    "            metrics = cross_validate_model_with_addon(dataset_per_try, sample_weights_per_try, feature_columns,\n",
    "                        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, \n",
    "                        outcome_class_priors, RandomForestClassifier, validation_weights=sample_cross_validation_age_weights,  \n",
    "                        criterion = param_combination[0], \n",
    "                        max_features = param_combination[1], max_depth=param_combination[2], \n",
    "                        n_estimators = param_combination[3])\n",
    "        return metrics['overall_metrics']\n",
    "\n",
    "\n",
    "    averaged_metrics, averaged_metrics_err =  bootstrap(dataset, bootstrapping_number_of_tries, sampling_function_per_try,\n",
    "                                  ml_function_per_try, return_errs=True, verbose=False)\n",
    "    print 'For param_combination: ', param_combination, ', AUC: ', averaged_metrics['without_dunno']['auc'], ' +/- ',\\\n",
    "                 averaged_metrics_err['without_dunno']['auc']\n",
    "    sys.stdout.flush()\n",
    "    return averaged_metrics, averaged_metrics_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_grid_search:\n",
    "    print 'feature_encoding_map: ', feature_encoding_map\n",
    "\n",
    "    n_autism = len(dataset[dataset['outcome']=='autism'].index)\n",
    "    n_not = len(dataset[dataset['outcome']=='not'].index)\n",
    "    print 'n_autism: ', n_autism\n",
    "    print 'n_not: ', n_not\n",
    "    print 'n_total: ', len(dataset.index)\n",
    "    assert n_autism + n_not == len(dataset.index)\n",
    "    print 'About to run grid search for ', run_desc\n",
    "    print 'ages in dataset: ', dataset['age_years'].value_counts()\n",
    "    print 'balance on: ', balance_dimensions\n",
    "    print 'Features list: ', feature_columns\n",
    "    print 'Details of features to use in grid search:'\n",
    "    for feature in feature_columns:\n",
    "        print feature, ', encoding: ', feature_encoding_map[feature]\n",
    "        print 'values: ', dataset[feature].value_counts()\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    \n",
    "    #this is where we output to\n",
    "    output_filename = output_directory+\"/\"+filename_prefix+\".gridSearch.modelParams.csv\"\n",
    "\n",
    "    #these are the ML model params that we will grid search over\n",
    "    criterion = [\"entropy\"]\n",
    "    max_features = ['log2', 'sqrt', 0.3]\n",
    "    max_depth = [4, 5, 6, 7, 8]\n",
    "    n_estimators = [100, 200]\n",
    "    param_combinations = get_combinations([criterion, max_features, max_depth, n_estimators])\n",
    "\n",
    "    #these are bootstrapping parameters\n",
    "    bootstrapping_number_of_tries = 10     #run every node in the grid search this many times and average out the resulting metrics\n",
    "    bootstrapping_sample_percent = 0.9    #for every run, random-sample this percentage of the dataset (stratified by target class) \n",
    "\n",
    "\n",
    "    #these static params are problem specific\n",
    "    n_folds = 20\n",
    "\n",
    "    #this dunno range param is outside of the ML model so let's fix it to some convenient values for now\n",
    "    dunno_range = (0.2,0.9)\n",
    "\n",
    "\n",
    "    reporting_function = lambda param_combination, (averaged_metrics, averaged_metrics_err): [ averaged_metrics['without_dunno']['auc'],\n",
    "                                                                  averaged_metrics_err['without_dunno']['auc'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_precision_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['reallife_precision_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                                  averaged_metrics_err['without_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_precision_per_class']['not'],\n",
    "                                                                  averaged_metrics['without_dunno']['reallife_precision_per_class']['not'],\n",
    "                                                                  averaged_metrics['without_dunno']['dataset_recall_per_class']['not'], \n",
    "                                                                  averaged_metrics_err['without_dunno']['dataset_recall_per_class']['not'],\n",
    "                                                                  n_autism,\n",
    "                                                                  n_not,\n",
    "                                                                 ]\n",
    "\n",
    "\n",
    "    #run grid search\n",
    "    report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "\n",
    "    #write outputs to file\n",
    "    output_file = open(output_filename,'w')\n",
    "    header = ','.join(['criterion','max_features', 'max_depth', 'n_trees','AUC','AUC err', 'autism precision [Dataset]', \n",
    "                   'autism precision [Reallife]', 'autism recall', 'autism recall err', 'not precision [Dataset]',\n",
    "                   'not precision [Reallife]', 'not recall', 'not recall err', 'n_autism', 'n_not'])\n",
    "    output_file.write(header+\"\\n\")\n",
    "    for line in report:\n",
    "        output_file.write(','.join([str(x) for x in line]))\n",
    "        output_file.write(\"\\n\")\n",
    "    output_file.close()\n",
    "\n",
    "    print 'Grid search done for run_desc: ', run_desc\n",
    "\n",
    "else:\n",
    "    print 'Skip grid search'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best dunno range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_dunno_grid_search = True\n",
    "if do_dunno_grid_search:\n",
    "    #this is where we output to\n",
    "    output_filename = output_directory+\"/\"+filename_prefix+\".dunnoGridSearch.modelParams.csv\"\n",
    "\n",
    "\n",
    "\n",
    "    #these are bootstrapping parameters\n",
    "    bootstrapping_number_of_tries = 10     #run every node in the grid search this many times and average out the resulting metrics\n",
    "    bootstrapping_sample_percent = 0.9    #for every run, random-sample this percentage of the dataset (stratified by target class) \n",
    "\n",
    "\n",
    "    #these static params are problem specific\n",
    "    n_folds = 20\n",
    "\n",
    "    #these params are outside of the ML model so let's fix them to some convenient values for now\n",
    "    dunno_range_min = [0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "    dunno_range_max = [0.65, 0.7, 0.75, 0.8, 0.85]\n",
    "    param_combinations = get_combinations([dunno_range_min, dunno_range_max])\n",
    "\n",
    "\n",
    "\n",
    "    def modeling_function(param_combination):\n",
    "        def sampling_function_per_try(dataset):\n",
    "            sample = subsample_per_class(dataset, outcome_column, {'autism':bootstrapping_sample_percent, 'not':bootstrapping_sample_percent})\n",
    "            return sample\n",
    "        def ml_function_per_try(dataset_per_try):\n",
    "            sample_weights_per_try = balance_dataset_on_dimensions(dataset_per_try, balance_dimensions)\n",
    "            sample_cross_validation_age_weights = balance_dataset_on_dimensions(dataset_per_try, ['age_years'], verbose=False)\n",
    "            #AS A HACK, here we bump 3 years olds sample weights by a factor of 3 relative to the 4 year olds and 2 year olds\n",
    "            if only_young_children==True:\n",
    "                for index in range(len(dataset_per_try)):\n",
    "                    if dataset_per_try['age_years'][index]==3:\n",
    "                        sample_weights_per_try[index] *= 3\n",
    "                    if dataset_per_try['age_years'][index]==2:\n",
    "                        sample_weights_per_try[index] *= 2\n",
    "            if only_young_children==False:\n",
    "                metrics = cross_validate_model(dataset_per_try, sample_weights_per_try, feature_columns, feature_encoding_map, outcome_column, (param_combination[0], param_combination[1]), n_folds, outcome_classes, outcome_class_priors, RandomForestClassifier,   validation_weights=sample_cross_validation_age_weights,  criterion = criterion, max_features = max_features,  max_depth = max_depth, n_estimators = n_estimators)\n",
    "\n",
    "            else:\n",
    "                metrics = cross_validate_model_with_addon(dataset_per_try, sample_weights_per_try, feature_columns, feature_encoding_map, outcome_column, (param_combination[0], param_combination[1]), n_folds, outcome_classes, outcome_class_priors, RandomForestClassifier,  validation_weights=sample_cross_validation_age_weights, criterion = criterion, max_features = max_features,  max_depth = max_depth, n_estimators = n_estimators)\n",
    "\n",
    "            return metrics['overall_metrics']\n",
    "\n",
    "        averaged_metrics =  bootstrap(dataset, bootstrapping_number_of_tries, sampling_function_per_try, ml_function_per_try)\n",
    "        print 'For param_combination: ', param_combination, ', coverage: ', averaged_metrics['with_dunno']['reallife_classification_rate'],\\\n",
    "                 ', autism recall: ', averaged_metrics['with_dunno']['dataset_recall_per_class_where_classified']['autism'], ', not recall: ',\\\n",
    "                  averaged_metrics['with_dunno']['dataset_recall_per_class_where_classified']['not'], ', auc: ', averaged_metrics['with_dunno']['auc']\n",
    "        return averaged_metrics\n",
    "\n",
    "\n",
    "\n",
    "    reporting_function = lambda param_combination, averaged_metrics: [ averaged_metrics['with_dunno']['dataset_classification_rate'],\n",
    "                                                              averaged_metrics['with_dunno']['reallife_classification_rate'],\n",
    "                                                              averaged_metrics['with_dunno']['dataset_precision_per_class']['autism'],\n",
    "                                                              averaged_metrics['with_dunno']['reallife_precision_per_class']['autism'],\n",
    "                                                              averaged_metrics['with_dunno']['dataset_recall_per_class']['autism'],\n",
    "                                                              averaged_metrics['with_dunno']['dataset_precision_per_class']['not'],\n",
    "                                                              averaged_metrics['with_dunno']['reallife_precision_per_class']['not'],\n",
    "                                                              averaged_metrics['with_dunno']['dataset_recall_per_class']['not'],\n",
    "                                                              averaged_metrics['with_dunno']['auc']\n",
    "                                                            ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #run grid search\n",
    "    report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "\n",
    "    #write outputs to file\n",
    "    output_file = open(output_filename,'w')\n",
    "    header = '\\t'.join(['dunno_range_min','dunno_range_max', \n",
    "                    'classification rate [Dataset]',\n",
    "                    'classification rate [Reallife]',\n",
    "                    'autism precision [Dataset]', \n",
    "                    'autism precision [Reallife]', \n",
    "                    'autism recall', \n",
    "                    'not precision [Dataset]', \n",
    "                    'not precision [Reallife]', \n",
    "                    'not recall',\n",
    "                    'auc'])\n",
    "    output_file.write(header+\"\\n\")\n",
    "    report = grid_search(modeling_function, param_combinations, reporting_function)\n",
    "    for line in report:\n",
    "        output_file.write('\\t'.join([str(x) for x in line]))\n",
    "        output_file.write(\"\\n\")\n",
    "    output_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimal model parameters and optimal dunno range to cross validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'max_features: ', max_features\n",
    "print 'criterion: ', criterion\n",
    "print 'n_estimators: ', n_estimators\n",
    "\n",
    "cross_validation_age_weights = balance_dataset_on_dimensions(dataset, ['age_years'], verbose=False)\n",
    "\n",
    "if only_young_children==False:\n",
    "    output = cross_validate_model(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier,  validation_weights=cross_validation_age_weights,  n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "        max_depth=max_depth, class_weight = class_weight)\n",
    "else:\n",
    "    output = cross_validate_model_with_addon(dataset, sample_weights, feature_columns,\n",
    "        feature_encoding_map, outcome_column, dunno_range, n_folds, outcome_classes, outcome_class_priors,\n",
    "        RandomForestClassifier, validation_weights=cross_validation_age_weights, n_estimators = n_estimators, criterion = criterion, max_features = max_features,\n",
    "        max_depth=max_depth, class_weight = class_weight)\n",
    "\n",
    "print_classifier_performance_metrics(outcome_classes, output['overall_metrics'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now build the final model using all corresponding samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where we output to\n",
    "output_filename = output_directory+filename_prefix+\".model\"\n",
    "\n",
    "#build model\n",
    "model, features, y_predicted_without_dunno, y_predicted_with_dunno, y_predicted_probs =\\\n",
    "    all_data_model(dataset, feature_columns, feature_encoding_map, outcome_column, sample_weights,\n",
    "    dunno_range, RandomForestClassifier,  n_estimators = n_estimators, criterion = criterion,\n",
    "    max_features = max_features, max_depth=max_depth, class_weight = class_weight)\n",
    "\n",
    "#save features into a separate file\n",
    "output_filename = output_directory+filename_prefix+\".features.txt\"\n",
    "output_file = open(output_filename,'w')\n",
    "ordered_features = sorted(zip(features, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "output_file.write(\"QUESTIONS BY IMPORTANCE:\\n\\n\")\n",
    "written_already = []\n",
    "for feature in [x[0].split('=')[0] for x in ordered_features]:\n",
    "    if feature not in written_already:\n",
    "        written_already += [feature]\n",
    "        output_file.write(feature)\n",
    "        output_file.write(\"\\n\")\n",
    "output_file.write(\"\\n\\nFEATURES BY IMPORTANCE:\\n\\n\")\n",
    "for pair in ordered_features:\n",
    "    output_file.write(str(pair[0])+\"\\t\"+str(pair[1]))\n",
    "    output_file.write(\"\\n\")\n",
    "output_file.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
